
## SWEEP 1: TB-hard-ONPOLICY-LearnedPB
program: off_policy.py
method: bayes
metric:
  goal: minimize
  name: jsd
parameters:
  n_trajectories:
    values:
      - 1000000
    distribution: categorical
  sampling_mode:
    values:
      - on_policy
    distribution: categorical
  final_epsilon:
    values:
      - 0
    distribution: categorical
  batch_size:
    values:
      - 64
    distribution: categorical
  schedule:
    values:
      - 1
      - 0.9
      - 0.5
      - 0.1
    distribution: categorical
  PB:
    values:
      - "learnable"
    distribution: categorical
  baseline:
    values:
      - "None"
    distribution: categorical
  seed:
    max: 200
    min: 50
    distribution: int_uniform
  mode:
    values:
      - tb
    distribution: categorical
  env:
    values:
      - hard
    distribution: categorical
  lr:
    distribution: log_uniform
    max: -3
    min: -9.2
  lr_Z:
    distribution: log_uniform
    max: -0.7
    min: -4.6
early_terminate:
  type: hyperband
  min_iter: 20